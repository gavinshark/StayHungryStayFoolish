"""
RAGAS Evaluation Demo - Main Entry Point

This script demonstrates the complete RAG system and RAGAS evaluation workflow.
"""

import os
import sys
from pathlib import Path

import yaml

from src.document_processor import DocumentProcessor
from src.vector_store import VectorStoreManager
from src.rag_chain import RAGChain
from src.evaluator import RagasEvaluator


def load_config() -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = Path("config/config.yaml")
    
    if not config_path.exists():
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° config/config.yaml é…ç½®æ–‡ä»¶")
        return {}
    
    with open(config_path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f) or {}


def get_openai_config(config: dict) -> dict:
    """
    è·å– OpenAI API é…ç½®
    
    - api_key, base_url: ä»ç³»ç»Ÿç¯å¢ƒå˜é‡è¯»å–
    - model, embedding_model: ä» config.yaml è¯»å–
    
    Args:
        config: é…ç½®å­—å…¸
    
    Returns:
        dict: åŒ…å« api_key, base_url, model, embedding_model
    """
    openai_config = config.get("openai", {})
    
    return {
        # ä»ç³»ç»Ÿç¯å¢ƒå˜é‡è¯»å–
        "api_key": os.environ.get("OPENAI_API_KEY"),
        "base_url": os.environ.get("OPENAI_BASE_URL"),
        # ä» config.yaml è¯»å–
        "model": openai_config.get("model", "gpt-3.5-turbo"),
        "embedding_model": openai_config.get("embedding_model", "text-embedding-v4"),
    }


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œå®Œæ•´çš„ RAG ç³»ç»Ÿå’Œ RAGAS è¯„æµ‹æµç¨‹"""
    print("=" * 60)
    print("ğŸš€ RAGAS Evaluation Demo")
    print("=" * 60)
    print()
    
    # 1. æ£€æŸ¥é…ç½®
    print("ğŸ“‹ æ­¥éª¤ 1: æ£€æŸ¥é…ç½®...")
    config = load_config()
    openai_config = get_openai_config(config)
    api_key = openai_config["api_key"]
    base_url = openai_config["base_url"]
    model = openai_config["model"]
    embedding_model = openai_config["embedding_model"]
    
    if not api_key:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° OpenAI API Key")
        print()
        print("è¯·è®¾ç½®ç³»ç»Ÿç¯å¢ƒå˜é‡:")
        print("  export OPENAI_API_KEY=your-key")
        print("  export OPENAI_BASE_URL=https://your-api-endpoint (å¯é€‰)")
        print()
        print("æ¨¡å‹é…ç½®åœ¨ config/config.yaml æ–‡ä»¶ä¸­:")
        print("  openai.model: gpt-3.5-turbo")
        print("  openai.embedding_model: text-embedding-v4")
        sys.exit(1)
    
    print("âœ… API Key å·²é…ç½®")
    if base_url:
        print(f"âœ… API Base URL: {base_url}")
    print(f"âœ… LLM Model: {model}")
    print(f"âœ… Embedding Model: {embedding_model}")
    print()
    
    # åŠ è½½å…¶ä»–é…ç½®
    chunk_size = config.get("document_processing", {}).get("chunk_size", 500)
    chunk_overlap = config.get("document_processing", {}).get("chunk_overlap", 50)
    retrieval_k = config.get("retrieval", {}).get("k", 4)
    
    # 2. åŠ è½½æ–‡æ¡£
    print("ğŸ“„ æ­¥éª¤ 2: åŠ è½½æ–‡æ¡£...")
    doc_processor = DocumentProcessor(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    
    documents_path = Path("data/documents")
    if not documents_path.exists() or not any(documents_path.glob("*.md")):
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°ç¤ºä¾‹æ–‡æ¡£")
        print(f"è¯·ç¡®ä¿ {documents_path} ç›®å½•ä¸‹æœ‰ Markdown æ–‡æ¡£")
        sys.exit(1)
    
    documents = doc_processor.load_directory(str(documents_path), glob="**/*.md")
    print(f"âœ… å·²åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£å—")
    print()
    
    # 3. åˆ›å»ºå‘é‡å­˜å‚¨
    print("ğŸ”¢ æ­¥éª¤ 3: åˆ›å»ºå‘é‡å­˜å‚¨...")
    
    vector_store = VectorStoreManager(api_key=api_key, embedding_model=embedding_model, base_url=base_url)
    vector_store.create_from_documents(documents)
    print(f"âœ… å‘é‡å­˜å‚¨å·²åˆ›å»ºï¼ŒåŒ…å« {vector_store.get_document_count()} ä¸ªå‘é‡ (æ¨¡å‹: {embedding_model})")
    print()
    
    # 4. åˆ›å»º RAG é“¾
    print("ğŸ”— æ­¥éª¤ 4: åˆ›å»º RAG é“¾...")
    rag_chain = RAGChain(
        vector_store_manager=vector_store,
        api_key=api_key,
        model=model,
        k=retrieval_k,
        base_url=base_url
    )
    print(f"âœ… RAG é“¾å·²åˆ›å»º (æ¨¡å‹: {model}, k={retrieval_k})")
    print()
    
    # 5. æµ‹è¯•æŸ¥è¯¢
    print("ğŸ’¬ æ­¥éª¤ 5: æµ‹è¯•æŸ¥è¯¢...")
    test_question = "ä»€ä¹ˆæ˜¯ RAGï¼Ÿ"
    print(f"é—®é¢˜: {test_question}")
    
    response = rag_chain.query(test_question)
    print(f"å›ç­”: {response.answer[:200]}..." if len(response.answer) > 200 else f"å›ç­”: {response.answer}")
    print(f"æ£€ç´¢åˆ° {len(response.contexts)} ä¸ªä¸Šä¸‹æ–‡")
    print()
    
    # 6. è¿è¡Œ RAGAS è¯„æµ‹
    print("ğŸ“Š æ­¥éª¤ 6: è¿è¡Œ RAGAS è¯„æµ‹...")
    dataset_path = Path("data/evaluation/test_dataset.json")
    
    if not dataset_path.exists():
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°è¯„æµ‹æ•°æ®é›†")
        print(f"è¯·ç¡®ä¿ {dataset_path} æ–‡ä»¶å­˜åœ¨")
        sys.exit(1)
    
    evaluator = RagasEvaluator(
        rag_chain,
        api_key=api_key,
        base_url=base_url,
        model=model,
        embedding_model=embedding_model
    )
    
    try:
        result, report = evaluator.run_evaluation(str(dataset_path))
        print()
        print(report)
    except Exception as e:
        print(f"âš ï¸  è¯„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¿™å¯èƒ½æ˜¯ç”±äº API è°ƒç”¨é™åˆ¶æˆ–ç½‘ç»œé—®é¢˜å¯¼è‡´çš„")
        print("è¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥ API é…ç½®")
    
    print()
    print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    main()
